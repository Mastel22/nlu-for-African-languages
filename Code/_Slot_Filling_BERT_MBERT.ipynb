{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AWusIgdObskV",
        "outputId": "bd6edb56-124e-407a-9242-f7975223ad50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !nvidia-smi"
      ],
      "metadata": {
        "id": "FRIrLtyAkO2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval -qqq\n",
        "# TODO: update this notebook to work with the latest version of transformers\n",
        "!pip install -q transformers==2.11.0"
      ],
      "metadata": {
        "id": "nOowDdspRyUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jfbzohmskRzZ",
        "outputId": "953d62d2-6fb2-4f08-e75c-958c9d2e727f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "XUIbeqcldJiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from tensorflow.keras.layers import Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler, ModelCheckpoint, TensorBoard\n",
        "from seqeval.metrics import classification_report\n",
        "from transformers import TFAutoModel\n",
        "from tensorflow.keras.layers import Dropout, Dense\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "import shutil\n",
        "import pickle\n",
        "from seqeval.metrics import classification_report\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "jbhE0jzNRvJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Data"
      ],
      "metadata": {
        "id": "JcQruOIhbL__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"/content/drive/MyDrive/JP Morgan/Data/translated_set/corrected slot labels data/translated_swa_test_slot_labels.xlsx\")"
      ],
      "metadata": {
        "id": "BvOfTo0c0Be-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns = {'utterance_swa\t':'words','slot_labels_swa':'word_labels','intent_swa':'intent_label'}, inplace = True)"
      ],
      "metadata": {
        "id": "rxtwtVrrhRdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"words\"] = df[\"utterance_swa\"]\n",
        "del df[\"utterance_swa\"]"
      ],
      "metadata": {
        "id": "oA3453r9hjXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "jtwgIm1Gfc1j",
        "outputId": "651bc4eb-1900-4a3b-9881-b7a59e7b1ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        utterance_en  \\\n",
              "0  what are the flights from tacoma to miami that...   \n",
              "1    what flights arrive at love field on june sixth   \n",
              "2  what meals are available on dl 468 which al ar...   \n",
              "3              list all tower air flights with meals   \n",
              "4  at the charlotte airport how many different ty...   \n",
              "\n",
              "                                      slot_labels_en intent_en  \\\n",
              "0  O O O O O B-fromloc.city_name O B-toloc.city_n...    flight   \n",
              "1  O O O O B-toloc.airport_name I-toloc.airport_n...    flight   \n",
              "2  O B-meal O O O B-airline_code B-flight_number ...      meal   \n",
              "3       O O B-airline_name I-airline_name O O B-meal    flight   \n",
              "4  O O B-city_name I-city_name O O O O O O O O O ...  aircraft   \n",
              "\n",
              "                                         word_labels intent_label  \\\n",
              "0  O O O O O O B-kutoka_mji_jina O B-hadi_mji_jin...        ndege   \n",
              "1  O O O O O O O B-hadi_uwanja_wa_ndege_jina I-ha...        ndege   \n",
              "2  B-chakula_nambari O O O B-ndege_kanuni B-ndege...          mlo   \n",
              "3  O O O O B-ndege_jina I-ndege_jina O B-chakula_...        ndege   \n",
              "4  O O O O O B-mji_jina O O O O O O B-ndege_jina ...        Ndege   \n",
              "\n",
              "                                               words  \n",
              "0  ni safari gani za ndege kutoka tacoma hadi mia...  \n",
              "1  ni ndege gani zinazofika kwenye uwanja wa love...  \n",
              "2  milo gani inapatikana kwenye dl 468 ambayo ina...  \n",
              "3       orodhesha ndege zote za Tower air  zina milo  \n",
              "4  kwenye uwanja wa ndege wa charlotte kuna aina ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5f8389d-2496-44c7-b90f-0e9f084cfe77\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utterance_en</th>\n",
              "      <th>slot_labels_en</th>\n",
              "      <th>intent_en</th>\n",
              "      <th>word_labels</th>\n",
              "      <th>intent_label</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what are the flights from tacoma to miami that...</td>\n",
              "      <td>O O O O O B-fromloc.city_name O B-toloc.city_n...</td>\n",
              "      <td>flight</td>\n",
              "      <td>O O O O O O B-kutoka_mji_jina O B-hadi_mji_jin...</td>\n",
              "      <td>ndege</td>\n",
              "      <td>ni safari gani za ndege kutoka tacoma hadi mia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what flights arrive at love field on june sixth</td>\n",
              "      <td>O O O O B-toloc.airport_name I-toloc.airport_n...</td>\n",
              "      <td>flight</td>\n",
              "      <td>O O O O O O O B-hadi_uwanja_wa_ndege_jina I-ha...</td>\n",
              "      <td>ndege</td>\n",
              "      <td>ni ndege gani zinazofika kwenye uwanja wa love...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what meals are available on dl 468 which al ar...</td>\n",
              "      <td>O B-meal O O O B-airline_code B-flight_number ...</td>\n",
              "      <td>meal</td>\n",
              "      <td>B-chakula_nambari O O O B-ndege_kanuni B-ndege...</td>\n",
              "      <td>mlo</td>\n",
              "      <td>milo gani inapatikana kwenye dl 468 ambayo ina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>list all tower air flights with meals</td>\n",
              "      <td>O O B-airline_name I-airline_name O O B-meal</td>\n",
              "      <td>flight</td>\n",
              "      <td>O O O O B-ndege_jina I-ndege_jina O B-chakula_...</td>\n",
              "      <td>ndege</td>\n",
              "      <td>orodhesha ndege zote za Tower air  zina milo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>at the charlotte airport how many different ty...</td>\n",
              "      <td>O O B-city_name I-city_name O O O O O O O O O ...</td>\n",
              "      <td>aircraft</td>\n",
              "      <td>O O O O O B-mji_jina O O O O O O B-ndege_jina ...</td>\n",
              "      <td>Ndege</td>\n",
              "      <td>kwenye uwanja wa ndege wa charlotte kuna aina ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5f8389d-2496-44c7-b90f-0e9f084cfe77')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5f8389d-2496-44c7-b90f-0e9f084cfe77 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5f8389d-2496-44c7-b90f-0e9f084cfe77');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = df.iloc[:300,5:8] \n",
        "# df_valid = df.iloc[350:450,5:8] \n",
        "# df_test = df.iloc[450:545,5:8] \n",
        "df_train, df_valid = train_test_split(df, test_size=0.2)"
      ],
      "metadata": {
        "id": "QH1bhCNBcaE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "t58xcFNfcmzI",
        "outputId": "83623a54-c0fe-4653-e93a-f84fb08889b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          utterance_en  \\\n",
              "714                  tampa to charlotte sunday morning   \n",
              "790            what is the seating capacity of the m80   \n",
              "421  show me the flights between los angeles and da...   \n",
              "118  are there any flights from boston to orlando c...   \n",
              "218  i need to take a united airlines flight on jun...   \n",
              "\n",
              "                                        slot_labels_en intent_en  \\\n",
              "714  B-fromloc.city_name O B-toloc.city_name B-depa...    flight   \n",
              "790                      O O O O O O O B-aircraft_code  capacity   \n",
              "421  O O O O O B-fromloc.city_name I-fromloc.city_n...    flight   \n",
              "118  O O O O O B-fromloc.city_name O B-toloc.city_n...    flight   \n",
              "218  O O O O O B-airline_name I-airline_name O O B-...    flight   \n",
              "\n",
              "                                           word_labels intent_label  \\\n",
              "714  B-kutoka_mji_jina O B-hadi.mji_jina B-kuondoka...        ndege   \n",
              "790                         O O O O O O B-ndege_kanuni        uwezo   \n",
              "421  O O O O O O B-kutoka_mji_jina I-kutoka_mji_jin...        ndege   \n",
              "118  O O O B-kutoka_mji_jina O B-hadi.mji_jina B-ku...        ndege   \n",
              "218                               O B-ndege_kanuni O O        ndege   \n",
              "\n",
              "                                                 words  \n",
              "714               tampa kwa charlotte jumapili asubuhi  \n",
              "790                     ni uwezo gani wa kuketi wa m80  \n",
              "421  nionyeshe safari za ndege kati ya los angeles ...  \n",
              "118   ndege gani kutoka boston hadi orlando zinazou...  \n",
              "218  nahitaji kuchukua ndege ya shirika la ndege la...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c87068df-023d-4733-bb98-d2d1e910f883\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utterance_en</th>\n",
              "      <th>slot_labels_en</th>\n",
              "      <th>intent_en</th>\n",
              "      <th>word_labels</th>\n",
              "      <th>intent_label</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>tampa to charlotte sunday morning</td>\n",
              "      <td>B-fromloc.city_name O B-toloc.city_name B-depa...</td>\n",
              "      <td>flight</td>\n",
              "      <td>B-kutoka_mji_jina O B-hadi.mji_jina B-kuondoka...</td>\n",
              "      <td>ndege</td>\n",
              "      <td>tampa kwa charlotte jumapili asubuhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>790</th>\n",
              "      <td>what is the seating capacity of the m80</td>\n",
              "      <td>O O O O O O O B-aircraft_code</td>\n",
              "      <td>capacity</td>\n",
              "      <td>O O O O O O B-ndege_kanuni</td>\n",
              "      <td>uwezo</td>\n",
              "      <td>ni uwezo gani wa kuketi wa m80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>show me the flights between los angeles and da...</td>\n",
              "      <td>O O O O O B-fromloc.city_name I-fromloc.city_n...</td>\n",
              "      <td>flight</td>\n",
              "      <td>O O O O O O B-kutoka_mji_jina I-kutoka_mji_jin...</td>\n",
              "      <td>ndege</td>\n",
              "      <td>nionyeshe safari za ndege kati ya los angeles ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>are there any flights from boston to orlando c...</td>\n",
              "      <td>O O O O O B-fromloc.city_name O B-toloc.city_n...</td>\n",
              "      <td>flight</td>\n",
              "      <td>O O O B-kutoka_mji_jina O B-hadi.mji_jina B-ku...</td>\n",
              "      <td>ndege</td>\n",
              "      <td>ndege gani kutoka boston hadi orlando zinazou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>i need to take a united airlines flight on jun...</td>\n",
              "      <td>O O O O O B-airline_name I-airline_name O O B-...</td>\n",
              "      <td>flight</td>\n",
              "      <td>O B-ndege_kanuni O O</td>\n",
              "      <td>ndege</td>\n",
              "      <td>nahitaji kuchukua ndege ya shirika la ndege la...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c87068df-023d-4733-bb98-d2d1e910f883')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c87068df-023d-4733-bb98-d2d1e910f883 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c87068df-023d-4733-bb98-d2d1e910f883');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BLS6_eVBceMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_valid.head()"
      ],
      "metadata": {
        "id": "KhKLOxQFSFKT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "191f9440-aef9-4c2a-ba3f-027970f8c683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          utterance_en  \\\n",
              "383  show me airlines that have flights between tor...   \n",
              "124        i need a flight from st. louis to charlotte   \n",
              "283       list all flights from cleveland to nashville   \n",
              "63               what cities does northwest fly out of   \n",
              "847  what are the flights between cincinnati and sa...   \n",
              "\n",
              "                                        slot_labels_en intent_en  \\\n",
              "383  O O O O O O O B-fromloc.city_name O B-toloc.ci...   airline   \n",
              "124  O O O O O B-fromloc.city_name I-fromloc.city_n...    flight   \n",
              "283    O O O O B-fromloc.city_name O B-toloc.city_name    flight   \n",
              "63                          O O O B-airline_name O O O      city   \n",
              "847  O O O O O B-fromloc.city_name O B-toloc.city_n...    flight   \n",
              "\n",
              "                                           word_labels      intent_label  \\\n",
              "383  O O O O O O O O O O O B-kutoka_mji_jina O B-ha...  shirika_la_ndege   \n",
              "124  O O O B-kutoka_mji_jina I-kutoka_mji_jina O B-...             ndege   \n",
              "283    O O O O O O B-kutoka_mji_jina O B-hadi.mji_jina             ndege   \n",
              "63                              O O O B-ndege_jina O O               mji   \n",
              "847  O O O O O O O B-kutoka_mji_jina O B-hadi.mji_j...             ndege   \n",
              "\n",
              "                                                 words  \n",
              "383  nionyeshe mashirika ya ndege ambayo yana safar...  \n",
              "124     nahitaji ndege kutoka St. Louis hadi charlotte  \n",
              "283  orodhesha safari zote za ndege kutoka Clevelan...  \n",
              "63               ni miji gani northwest inaruka kutoka  \n",
              "847  ni safari gani za ndege kati ya cincinnati na ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65fc77fd-6f56-42de-907c-489b974aeb1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utterance_en</th>\n",
              "      <th>slot_labels_en</th>\n",
              "      <th>intent_en</th>\n",
              "      <th>word_labels</th>\n",
              "      <th>intent_label</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>show me airlines that have flights between tor...</td>\n",
              "      <td>O O O O O O O B-fromloc.city_name O B-toloc.ci...</td>\n",
              "      <td>airline</td>\n",
              "      <td>O O O O O O O O O O O B-kutoka_mji_jina O B-ha...</td>\n",
              "      <td>shirika_la_ndege</td>\n",
              "      <td>nionyeshe mashirika ya ndege ambayo yana safar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>i need a flight from st. louis to charlotte</td>\n",
              "      <td>O O O O O B-fromloc.city_name I-fromloc.city_n...</td>\n",
              "      <td>flight</td>\n",
              "      <td>O O O B-kutoka_mji_jina I-kutoka_mji_jina O B-...</td>\n",
              "      <td>ndege</td>\n",
              "      <td>nahitaji ndege kutoka St. Louis hadi charlotte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>list all flights from cleveland to nashville</td>\n",
              "      <td>O O O O B-fromloc.city_name O B-toloc.city_name</td>\n",
              "      <td>flight</td>\n",
              "      <td>O O O O O O B-kutoka_mji_jina O B-hadi.mji_jina</td>\n",
              "      <td>ndege</td>\n",
              "      <td>orodhesha safari zote za ndege kutoka Clevelan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>what cities does northwest fly out of</td>\n",
              "      <td>O O O B-airline_name O O O</td>\n",
              "      <td>city</td>\n",
              "      <td>O O O B-ndege_jina O O</td>\n",
              "      <td>mji</td>\n",
              "      <td>ni miji gani northwest inaruka kutoka</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>what are the flights between cincinnati and sa...</td>\n",
              "      <td>O O O O O B-fromloc.city_name O B-toloc.city_n...</td>\n",
              "      <td>flight</td>\n",
              "      <td>O O O O O O O B-kutoka_mji_jina O B-hadi.mji_j...</td>\n",
              "      <td>ndege</td>\n",
              "      <td>ni safari gani za ndege kati ya cincinnati na ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65fc77fd-6f56-42de-907c-489b974aeb1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65fc77fd-6f56-42de-907c-489b974aeb1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65fc77fd-6f56-42de-907c-489b974aeb1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-RqFpLgqI6u"
      },
      "source": [
        "\n",
        "## A First Model: Intent Classification (Sentence Level)\n",
        "\n",
        "Let's ignore the slot filling task for now and let's try to build a sentence level classifier by fine-tuning a pre-trained Transformer-based model using the `huggingface/transformers` package that provides both TF2/Keras and Pytorch APIs.\n",
        "\n",
        "### The BERT Tokenizer\n",
        "\n",
        "First let's load a pre-trained tokenizer and test it on a test sentence from the training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8waNlSO-tkkP"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "model_name = \"bert-base-multilingual-cased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing word tokenization using Bert"
      ],
      "metadata": {
        "id": "E2kDm0-tbeXb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfIeG0rvuywQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "823e48d0-1baa-44f5-82c3-d66931b1c028"
      },
      "source": [
        "first_sentence = df_train.iloc[0][\"words\"]\n",
        "first_sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tampa kwa charlotte jumapili asubuhi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1NdNH7btohS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cd072c4-a6c9-476e-8618-942f4eae4459"
      },
      "source": [
        "encoding = tokenizer.encode(first_sentence)\n",
        "print(tokenizer.convert_ids_to_tokens(encoding))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'tam', '##pa', 'kwa', 'char', '##lotte', 'ju', '##ma', '##pili', 'asub', '##uh', '##i', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV0nkrwDvVlc"
      },
      "source": [
        "It can be noticed that BERT uses subword tokens so the length of the tokenized sentence is likely to be larger than the number of words in the sentence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXvGt8fAmW6o"
      },
      "source": [
        "Remarks:\n",
        "\n",
        "- The first token `[CLS]` is used by the pre-training task for sequence classification.\n",
        "- The last token `[SEP]` is a separator for the pre-training task that classifiies if a pair of sentences are consecutive in a corpus or not (next sentence prediction)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "wqgWOetUcemB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the length of sequences after tokenization, so that we could assign them to equal dummy vectors in the training set"
      ],
      "metadata": {
        "id": "EveW9CTmcjLT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDRfHq45uXtE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "35bd38f7-466e-4317-b063-efcd08b5e31c"
      },
      "source": [
        "train_sequence_lengths = [len(tokenizer.encode(text))\n",
        "                          for text in df_train[\"words\"]]\n",
        "plt.hist(train_sequence_lengths, bins=30)\n",
        "plt.title(f\"max sequence length: {max(train_sequence_lengths)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'max sequence length: 55')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e80rCfLZo0ms"
      },
      "source": [
        "[link text](https://)The mapping can be introspected in the `tokenizer.vocab` attribute:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q399LhkCjCa8"
      },
      "source": [
        "### Encoding the Dataset with the Tokenizer\n",
        "\n",
        "Encoding the full train / valid and test sets with Bert tokenizer to get a padded integer numpy arrays:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI7fXQKmpQFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "659c51d6-ff9c-4faa-cb5d-e31014178c40"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def encode_dataset(tokenizer, text_sequences, max_length):\n",
        "    token_ids = np.zeros(shape=(len(text_sequences), max_length),\n",
        "                         dtype=np.int32)\n",
        "    for i, text_sequence in enumerate(text_sequences):\n",
        "        encoded = tokenizer.encode(text_sequence)\n",
        "        token_ids[i, 0:len(encoded)] = encoded\n",
        "    attention_masks = (token_ids != 0).astype(np.int32)\n",
        "    return {\"input_ids\": token_ids, \"attention_masks\": attention_masks}\n",
        "\n",
        "encoded_train = encode_dataset(tokenizer, df_train[\"words\"], 60)\n",
        "encoded_train[\"input_ids\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  101, 14918, 11359, ...,     0,     0,     0],\n",
              "       [  101, 10414,   189, ...,     0,     0,     0],\n",
              "       [  101, 10414, 16131, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101, 16002, 20193, ...,     0,     0,     0],\n",
              "       [  101, 16002, 20193, ...,     0,     0,     0],\n",
              "       [  101, 16002, 20193, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPZjHqv3rdY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3afc784-75c2-4607-cb39-8ba02a9eb90d"
      },
      "source": [
        "encoded_train[\"attention_masks\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLiTJg4Sqwuk"
      },
      "source": [
        "encoded_valid = encode_dataset(tokenizer, df_valid[\"words\"], 60)\n",
        "# encoded_test = encode_dataset(tokenizer, df_test[\"words\"], 90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIgGo8ECtvfy"
      },
      "source": [
        "### Encoding the Sequence Classification Targets\n",
        "\n",
        "To do so we build a simple mapping from the auxiliary files:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_out_tokenizer = Tokenizer(filters='!\"#$%&()*+,/:;<=>?@[\\\\]^`{|}~\\t\\n', oov_token=\"UNK\",lower=False)"
      ],
      "metadata": {
        "id": "cBHehraHRilo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Preprocessing\n",
        "\n",
        "df_train.fillna('O',inplace = True)\n",
        "\n",
        "df_valid.fillna('O',inplace = True)"
      ],
      "metadata": {
        "id": "3q3p80CziFlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_out_tokenizer.fit_on_texts(df_train[\"word_labels\"].tolist())"
      ],
      "metadata": {
        "id": "m6z1Q9O5aBpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_out_tokenizer.fit_on_texts(df_valid[\"word_labels\"].tolist())"
      ],
      "metadata": {
        "id": "NZEXJYjaaC4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_out_word_to_index = seq_out_tokenizer.word_index\n",
        "len(seq_out_word_to_index)"
      ],
      "metadata": {
        "id": "HMaj59KkSs-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ac7a3e-2512-413b-ef55-ff84daa3d8c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "144"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_out_word_to_index"
      ],
      "metadata": {
        "id": "07ERpux0Sz1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bda25ab-0da9-48d6-ad92-8d55329fcb35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'UNK': 1,\n",
              " 'O': 2,\n",
              " 'B-hadi.mji_jina': 3,\n",
              " 'B-kutoka_mji_jina': 4,\n",
              " 'I-hadi.mji_jina': 5,\n",
              " 'B-kuondoka_terehe.siku_jina': 6,\n",
              " 'I-kutoka_mji_jina': 7,\n",
              " 'B-ndege_jina': 8,\n",
              " 'cha': 9,\n",
              " 'siku': 10,\n",
              " 'B-kuondoka_muda.kipindi': 11,\n",
              " 'I-safari_ya_kurudi': 12,\n",
              " 'B-kutoka.mji_jina': 13,\n",
              " 'B-hadi_mji_jina': 14,\n",
              " 'I-kufika_muda.muda': 15,\n",
              " 'B-ndege_kanuni': 16,\n",
              " 'I-kuondoka_muda.muda': 17,\n",
              " 'I-ndege_jina': 18,\n",
              " 'B-safari_ya_kurudi': 19,\n",
              " 'B-mji_jina': 20,\n",
              " 'B-kuondoka_muda.muda_jamaa': 21,\n",
              " 'B-kuondoka_muda.muda': 22,\n",
              " 'B-kuondoka_tarehe.siku_jina': 23,\n",
              " 'B-kufika_muda.muda': 24,\n",
              " 'I-ndege_acha': 25,\n",
              " 'I-hadi_mji_jina': 26,\n",
              " 'B-gharama_jamaa': 27,\n",
              " 'I-kategoria_aina': 28,\n",
              " 'B-kuondoka_muda.kipindi_cha_siku': 29,\n",
              " 'I-kuondoka_terehe.siku_nambari': 30,\n",
              " 'I-gharama_jamaa': 31,\n",
              " 'I-kutoka.mji_jina': 32,\n",
              " 'B-chakula_nambari': 33,\n",
              " 'B-ndege_mod': 34,\n",
              " 'B-ndege_acha': 35,\n",
              " 'I-mji_jina': 36,\n",
              " 'B-kufika_muda.muda_jamaa': 37,\n",
              " 'B-kategoria_aina': 38,\n",
              " 'I-uchumi': 39,\n",
              " 'B-kuondoka_terehe.mwezi_jina': 40,\n",
              " 'B-kuondoka_terehe.siku_nambari': 41,\n",
              " 'I-kuondoka_tarehe.siku_nambari': 42,\n",
              " 'B-kuondoka_tarehe.siku_nambari': 43,\n",
              " 'B-msimbo_msingi_wa_nauli': 44,\n",
              " 'B-kuondoka_tarehe.mwezi_jina': 45,\n",
              " 'B-uwanjya_wa_ndege_jina': 46,\n",
              " 'B-kutoka_uwanja_wa_ndege_jina': 47,\n",
              " 'I-ndege_mod': 48,\n",
              " 'I-kuondoka_muda.kipindi': 49,\n",
              " 'B-acha_mji_jina': 50,\n",
              " 'B-ndege_days': 51,\n",
              " 'I-ndege_days': 52,\n",
              " 'B-uchumi': 53,\n",
              " 'B-kuondoka_terehe.tarehe_jamaa': 54,\n",
              " 'B-uwanjya_wa_ndege_kanuni': 55,\n",
              " 'B-kufika_tarehe.siku_jina': 56,\n",
              " 'B-ndege_number': 57,\n",
              " 'I-mlo_maelezo': 58,\n",
              " 'B-kuondoka_tarehe.tarehe_jamaa': 59,\n",
              " 'B-kufika_muda.kipindi_cha_siku': 60,\n",
              " 'B-kufika_muda.kuanza_muda': 61,\n",
              " 'B-kufika_muda.mwisho_muda': 62,\n",
              " 'I-kufika_muda.mwisho_muda': 63,\n",
              " 'B-bila_kurudi': 64,\n",
              " 'I-bila_kurudi': 65,\n",
              " 'B-depart_time.period_mod': 66,\n",
              " 'I-safari_kurudi': 67,\n",
              " 'I-chakula_nambari_description': 68,\n",
              " 'I-safiri_bila_kurudi': 69,\n",
              " 'B-kuunganisha': 70,\n",
              " 'B-kutoka_uwanja_wa_ndege_kanuni': 71,\n",
              " 'I-acha_mji_jina': 72,\n",
              " 'I-kutoka_uwanja_wa_ndege_jina': 73,\n",
              " 'B-kuondoka_terehe.leo_jamaa': 74,\n",
              " 'B-hadi.jina_la_jimbo': 75,\n",
              " 'B-usafiri_aina': 76,\n",
              " 'I-uwanjya_wa_ndege_jina': 77,\n",
              " 'B-hadi_uwanja_wa_ndege_kanuni': 78,\n",
              " 'B-mlo_maelezo': 79,\n",
              " 'B-chakula_nambari_description': 80,\n",
              " 'B-kizuizi_kanuni': 81,\n",
              " 'B-hadi_uwanja_wa_ndege_jina': 82,\n",
              " 'B-kuondoka_terehe.mwaka': 83,\n",
              " 'B-safari_kurudi': 84,\n",
              " 'B-safiri_bila_kurudi': 85,\n",
              " 'B-kufika_tarehe.siku_nambari': 86,\n",
              " 'I-kizuizi_kanuni': 87,\n",
              " 'B-kipicha_cha_siku': 88,\n",
              " 'B-ndege_hali': 89,\n",
              " 'B-acha.mji_jina': 90,\n",
              " 'B-nauli_kiasi': 91,\n",
              " 'I-nauli_kiasi': 92,\n",
              " 'B-kurudi_tarehe.siku_jamaa': 93,\n",
              " 'I-kufika_muda.muda_jamaa': 94,\n",
              " 'B-kuondoka_tarehe.leo_jamaa': 95,\n",
              " 'B-kuondoka_muda.kuanza_muda': 96,\n",
              " 'B-kuondoka_muda.mwisho_muda': 97,\n",
              " 'B-siku_kanuni': 98,\n",
              " 'B-kupitia.mji_jina': 99,\n",
              " 'B-kutoka.jina_la_jimbo': 100,\n",
              " 'I-kuunganisha': 101,\n",
              " 'B-kuondoka.jina_la_jimbo': 102,\n",
              " 'I-usafiri_aina': 103,\n",
              " 'I-kipicha_cha_siku': 104,\n",
              " 'B-kuondoka.wakati_jamaa': 105,\n",
              " 'B-kurudi_tarehe.siku_jina': 106,\n",
              " 'I-ndege_hali': 107,\n",
              " 'I-hadi_uwanja_wa_ndege_jina': 108,\n",
              " 'B-kufika_terehe.mwezi_jina': 109,\n",
              " 'I-darasa_aina': 110,\n",
              " 'B-kuondoka_saa.wakati_jamaa': 111,\n",
              " 'B-kuondoka_wakati.wakati': 112,\n",
              " 'I-kuondoka_wakati.wakati': 113,\n",
              " 'B-au': 114,\n",
              " 'B-ndege_nambari': 115,\n",
              " 'I-kufika_muda.kuanza_muda': 116,\n",
              " 'I-acha.mji_jina': 117,\n",
              " 'B-uwanja_wa_ndege_jina': 118,\n",
              " 'I-kurudi_tarehe.siku_jamaa': 119,\n",
              " 'I-kuondoka_muda.kipindi_cha_siku': 120,\n",
              " 'B-hadi.jimbo_jina': 121,\n",
              " 'B-kufika_tarehe.mwezi_jina': 122,\n",
              " 'B-kuondoka.mji_jina': 123,\n",
              " 'I-kuondoka.mji_jina': 124,\n",
              " 'B-kutoka_muda.kipindi_cha_siku': 125,\n",
              " 'I-kuondoka_muda.mwisho_muda': 126,\n",
              " 'B-bila_kukoma': 127,\n",
              " 'I-bila_kukoma': 128,\n",
              " 'B-kufika_muda.mwisho_muda.kipindi_cha_siku': 129,\n",
              " 'B-kuweka_nafasi_aina': 130,\n",
              " 'B-kuondoka_terehe.kesho': 131,\n",
              " 'B-kurudi_tarehe.tarehe_jamaa': 132,\n",
              " 'I-kurudi_tarehe.tarehe_jamaa': 133,\n",
              " 'I-kupitia.mji_jina': 134,\n",
              " 'B-darasa_aina': 135,\n",
              " 'B-mapumziko': 136,\n",
              " 'B-kuodoka_tarehe.leo_jamaa': 137,\n",
              " 'B-kufika_tarehe.tarehe_jamaa': 138,\n",
              " 'B-kutoka_mji_kanuni': 139,\n",
              " 'B-siku_jina': 140,\n",
              " 'B-acha_uwanja_wa_ndege_kanuni': 141,\n",
              " 'B-bila_kikomo': 142,\n",
              " 'I-bila_kikomo': 143,\n",
              " 'I-B-kuondoka_tarehe.siku_jina': 144}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqcSXpgOwcbX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89575094-ce00-4e81-e609-b42bd48a0009"
      },
      "source": [
        "intent_names = set(df_train.intent_label)\n",
        "intent_map = dict((label, idx) for idx, label in enumerate(intent_names))\n",
        "intent_map"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'siku_jina': 0,\n",
              " 'umbali': 1,\n",
              " 'ndege#atis_nauli_ya_ndege': 2,\n",
              " 'muda_wa_ndege': 3,\n",
              " 'ndege_nambari#atis_shirika_la_ndege': 4,\n",
              " 'ufupisho': 5,\n",
              " 'ndege#atis_shirika_la_ndege': 6,\n",
              " 'mlo': 7,\n",
              " 'kiasi': 8,\n",
              " 'Ndege': 9,\n",
              " 'ndege_nambari': 10,\n",
              " 'mji': 11,\n",
              " 'uwezo': 12,\n",
              " 'uwanja_wa_ndege': 13,\n",
              " 'ndege': 14,\n",
              " 'shirika_la_ndege': 15,\n",
              " 'nauli_ya_ndege#atis_ndege': 16,\n",
              " 'huduma_ya_ardhini': 17,\n",
              " 'nauli_ya_ardhini': 18,\n",
              " 'nauli_ya_ndege': 19}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFjLpaFxxQk6"
      },
      "source": [
        "intent_train = df_train[\"intent_label\"].map(intent_map).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRbvVXuPndoN"
      },
      "source": [
        "intent_valid = df_valid[\"intent_label\"].map(intent_map).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5TuDZR26jwq"
      },
      "source": [
        "### Loading and Feeding a Pretrained BERT model\n",
        "\n",
        "Loading a pretrained BERT Large model using the [huggingface transformers](https://github.com/huggingface/transformers) package:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73ZrDDm-0wYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c24e17e7-bc1d-4f9d-98c7-5ed89cbd62fb"
      },
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "large_bert_model = TFAutoModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "large_bert_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_bert_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  177853440 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 177,853,440\n",
            "Trainable params: 177,853,440\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwgRCE2h6QUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f5b05de-eb94-4f32-899f-6fc8ee5ed8e1"
      },
      "source": [
        "encoded_valid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': array([[  101, 10414, 16131, ...,     0,     0,     0],\n",
              "        [  101, 62137, 10213, ...,     0,     0,     0],\n",
              "        [  101, 16002, 20193, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101, 16002, 20193, ...,     0,     0,     0],\n",
              "        [  101, 69397, 11856, ...,     0,     0,     0],\n",
              "        [  101, 11057, 13369, ...,     0,     0,     0]], dtype=int32),\n",
              " 'attention_masks': array([[1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0]], dtype=int32)}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htMv_pQt5aYl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb2e26e-7b72-48f5-e561-5941d34fcb54"
      },
      "source": [
        "outputs = large_bert_model(encoded_valid)\n",
        "len(outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkwN4INi8eSh"
      },
      "source": [
        "The **first ouput** of the BERT model is a tensor with shape: `(batch_size, seq_len, output_dim)` which computes **features for each token in the input sequence**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PoQyA_A7CS4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5458c307-e656-464d-9734-e1c0c4dd7c43"
      },
      "source": [
        "outputs[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([179, 60, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxjU9Wpi8vyM"
      },
      "source": [
        "The **second output** of the BERT model is a tensor with shape `(batch_size, output_dim)` which is the vector representation of the special token `[CLS]`. This vector is typically used as a **pooled representation for the sequence as a whole**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbg9Yd6MTlQQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ec09fe-bf59-4d35-bbf3-9b639be02053"
      },
      "source": [
        "outputs[1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([179, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mapping slots to the corresponding indexes"
      ],
      "metadata": {
        "id": "PoTr6Et0hoKm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgYp8XkWMkpx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cea1da7-15fa-4c16-bc25-af97b4eb33f4"
      },
      "source": [
        "slot_names = [\"[PAD]\"]\n",
        "slot_names += list(seq_out_word_to_index.keys())[1:]\n",
        "slot_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[PAD]',\n",
              " 'O',\n",
              " 'B-hadi.mji_jina',\n",
              " 'B-kutoka_mji_jina',\n",
              " 'I-hadi.mji_jina',\n",
              " 'B-kuondoka_terehe.siku_jina',\n",
              " 'I-kutoka_mji_jina',\n",
              " 'B-ndege_jina',\n",
              " 'cha',\n",
              " 'siku',\n",
              " 'B-kuondoka_muda.kipindi',\n",
              " 'I-safari_ya_kurudi',\n",
              " 'B-kutoka.mji_jina',\n",
              " 'B-hadi_mji_jina',\n",
              " 'I-kufika_muda.muda',\n",
              " 'B-ndege_kanuni',\n",
              " 'I-kuondoka_muda.muda',\n",
              " 'I-ndege_jina',\n",
              " 'B-safari_ya_kurudi',\n",
              " 'B-mji_jina',\n",
              " 'B-kuondoka_muda.muda_jamaa',\n",
              " 'B-kuondoka_muda.muda',\n",
              " 'B-kuondoka_tarehe.siku_jina',\n",
              " 'B-kufika_muda.muda',\n",
              " 'I-ndege_acha',\n",
              " 'I-hadi_mji_jina',\n",
              " 'B-gharama_jamaa',\n",
              " 'I-kategoria_aina',\n",
              " 'B-kuondoka_muda.kipindi_cha_siku',\n",
              " 'I-kuondoka_terehe.siku_nambari',\n",
              " 'I-gharama_jamaa',\n",
              " 'I-kutoka.mji_jina',\n",
              " 'B-chakula_nambari',\n",
              " 'B-ndege_mod',\n",
              " 'B-ndege_acha',\n",
              " 'I-mji_jina',\n",
              " 'B-kufika_muda.muda_jamaa',\n",
              " 'B-kategoria_aina',\n",
              " 'I-uchumi',\n",
              " 'B-kuondoka_terehe.mwezi_jina',\n",
              " 'B-kuondoka_terehe.siku_nambari',\n",
              " 'I-kuondoka_tarehe.siku_nambari',\n",
              " 'B-kuondoka_tarehe.siku_nambari',\n",
              " 'B-msimbo_msingi_wa_nauli',\n",
              " 'B-kuondoka_tarehe.mwezi_jina',\n",
              " 'B-uwanjya_wa_ndege_jina',\n",
              " 'B-kutoka_uwanja_wa_ndege_jina',\n",
              " 'I-ndege_mod',\n",
              " 'I-kuondoka_muda.kipindi',\n",
              " 'B-acha_mji_jina',\n",
              " 'B-ndege_days',\n",
              " 'I-ndege_days',\n",
              " 'B-uchumi',\n",
              " 'B-kuondoka_terehe.tarehe_jamaa',\n",
              " 'B-uwanjya_wa_ndege_kanuni',\n",
              " 'B-kufika_tarehe.siku_jina',\n",
              " 'B-ndege_number',\n",
              " 'I-mlo_maelezo',\n",
              " 'B-kuondoka_tarehe.tarehe_jamaa',\n",
              " 'B-kufika_muda.kipindi_cha_siku',\n",
              " 'B-kufika_muda.kuanza_muda',\n",
              " 'B-kufika_muda.mwisho_muda',\n",
              " 'I-kufika_muda.mwisho_muda',\n",
              " 'B-bila_kurudi',\n",
              " 'I-bila_kurudi',\n",
              " 'B-depart_time.period_mod',\n",
              " 'I-safari_kurudi',\n",
              " 'I-chakula_nambari_description',\n",
              " 'I-safiri_bila_kurudi',\n",
              " 'B-kuunganisha',\n",
              " 'B-kutoka_uwanja_wa_ndege_kanuni',\n",
              " 'I-acha_mji_jina',\n",
              " 'I-kutoka_uwanja_wa_ndege_jina',\n",
              " 'B-kuondoka_terehe.leo_jamaa',\n",
              " 'B-hadi.jina_la_jimbo',\n",
              " 'B-usafiri_aina',\n",
              " 'I-uwanjya_wa_ndege_jina',\n",
              " 'B-hadi_uwanja_wa_ndege_kanuni',\n",
              " 'B-mlo_maelezo',\n",
              " 'B-chakula_nambari_description',\n",
              " 'B-kizuizi_kanuni',\n",
              " 'B-hadi_uwanja_wa_ndege_jina',\n",
              " 'B-kuondoka_terehe.mwaka',\n",
              " 'B-safari_kurudi',\n",
              " 'B-safiri_bila_kurudi',\n",
              " 'B-kufika_tarehe.siku_nambari',\n",
              " 'I-kizuizi_kanuni',\n",
              " 'B-kipicha_cha_siku',\n",
              " 'B-ndege_hali',\n",
              " 'B-acha.mji_jina',\n",
              " 'B-nauli_kiasi',\n",
              " 'I-nauli_kiasi',\n",
              " 'B-kurudi_tarehe.siku_jamaa',\n",
              " 'I-kufika_muda.muda_jamaa',\n",
              " 'B-kuondoka_tarehe.leo_jamaa',\n",
              " 'B-kuondoka_muda.kuanza_muda',\n",
              " 'B-kuondoka_muda.mwisho_muda',\n",
              " 'B-siku_kanuni',\n",
              " 'B-kupitia.mji_jina',\n",
              " 'B-kutoka.jina_la_jimbo',\n",
              " 'I-kuunganisha',\n",
              " 'B-kuondoka.jina_la_jimbo',\n",
              " 'I-usafiri_aina',\n",
              " 'I-kipicha_cha_siku',\n",
              " 'B-kuondoka.wakati_jamaa',\n",
              " 'B-kurudi_tarehe.siku_jina',\n",
              " 'I-ndege_hali',\n",
              " 'I-hadi_uwanja_wa_ndege_jina',\n",
              " 'B-kufika_terehe.mwezi_jina',\n",
              " 'I-darasa_aina',\n",
              " 'B-kuondoka_saa.wakati_jamaa',\n",
              " 'B-kuondoka_wakati.wakati',\n",
              " 'I-kuondoka_wakati.wakati',\n",
              " 'B-au',\n",
              " 'B-ndege_nambari',\n",
              " 'I-kufika_muda.kuanza_muda',\n",
              " 'I-acha.mji_jina',\n",
              " 'B-uwanja_wa_ndege_jina',\n",
              " 'I-kurudi_tarehe.siku_jamaa',\n",
              " 'I-kuondoka_muda.kipindi_cha_siku',\n",
              " 'B-hadi.jimbo_jina',\n",
              " 'B-kufika_tarehe.mwezi_jina',\n",
              " 'B-kuondoka.mji_jina',\n",
              " 'I-kuondoka.mji_jina',\n",
              " 'B-kutoka_muda.kipindi_cha_siku',\n",
              " 'I-kuondoka_muda.mwisho_muda',\n",
              " 'B-bila_kukoma',\n",
              " 'I-bila_kukoma',\n",
              " 'B-kufika_muda.mwisho_muda.kipindi_cha_siku',\n",
              " 'B-kuweka_nafasi_aina',\n",
              " 'B-kuondoka_terehe.kesho',\n",
              " 'B-kurudi_tarehe.tarehe_jamaa',\n",
              " 'I-kurudi_tarehe.tarehe_jamaa',\n",
              " 'I-kupitia.mji_jina',\n",
              " 'B-darasa_aina',\n",
              " 'B-mapumziko',\n",
              " 'B-kuodoka_tarehe.leo_jamaa',\n",
              " 'B-kufika_tarehe.tarehe_jamaa',\n",
              " 'B-kutoka_mji_kanuni',\n",
              " 'B-siku_jina',\n",
              " 'B-acha_uwanja_wa_ndege_kanuni',\n",
              " 'B-bila_kikomo',\n",
              " 'I-bila_kikomo',\n",
              " 'I-B-kuondoka_tarehe.siku_jina']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slot_map = {}\n",
        "for label in slot_names:\n",
        "    slot_map[label] = len(slot_map)\n",
        "slot_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FngyzONckFR_",
        "outputId": "b250c100-44bb-4274-9755-396265522e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'[PAD]': 0,\n",
              " 'O': 1,\n",
              " 'B-hadi.mji_jina': 2,\n",
              " 'B-kutoka_mji_jina': 3,\n",
              " 'I-hadi.mji_jina': 4,\n",
              " 'B-kuondoka_terehe.siku_jina': 5,\n",
              " 'I-kutoka_mji_jina': 6,\n",
              " 'B-ndege_jina': 7,\n",
              " 'cha': 8,\n",
              " 'siku': 9,\n",
              " 'B-kuondoka_muda.kipindi': 10,\n",
              " 'I-safari_ya_kurudi': 11,\n",
              " 'B-kutoka.mji_jina': 12,\n",
              " 'B-hadi_mji_jina': 13,\n",
              " 'I-kufika_muda.muda': 14,\n",
              " 'B-ndege_kanuni': 15,\n",
              " 'I-kuondoka_muda.muda': 16,\n",
              " 'I-ndege_jina': 17,\n",
              " 'B-safari_ya_kurudi': 18,\n",
              " 'B-mji_jina': 19,\n",
              " 'B-kuondoka_muda.muda_jamaa': 20,\n",
              " 'B-kuondoka_muda.muda': 21,\n",
              " 'B-kuondoka_tarehe.siku_jina': 22,\n",
              " 'B-kufika_muda.muda': 23,\n",
              " 'I-ndege_acha': 24,\n",
              " 'I-hadi_mji_jina': 25,\n",
              " 'B-gharama_jamaa': 26,\n",
              " 'I-kategoria_aina': 27,\n",
              " 'B-kuondoka_muda.kipindi_cha_siku': 28,\n",
              " 'I-kuondoka_terehe.siku_nambari': 29,\n",
              " 'I-gharama_jamaa': 30,\n",
              " 'I-kutoka.mji_jina': 31,\n",
              " 'B-chakula_nambari': 32,\n",
              " 'B-ndege_mod': 33,\n",
              " 'B-ndege_acha': 34,\n",
              " 'I-mji_jina': 35,\n",
              " 'B-kufika_muda.muda_jamaa': 36,\n",
              " 'B-kategoria_aina': 37,\n",
              " 'I-uchumi': 38,\n",
              " 'B-kuondoka_terehe.mwezi_jina': 39,\n",
              " 'B-kuondoka_terehe.siku_nambari': 40,\n",
              " 'I-kuondoka_tarehe.siku_nambari': 41,\n",
              " 'B-kuondoka_tarehe.siku_nambari': 42,\n",
              " 'B-msimbo_msingi_wa_nauli': 43,\n",
              " 'B-kuondoka_tarehe.mwezi_jina': 44,\n",
              " 'B-uwanjya_wa_ndege_jina': 45,\n",
              " 'B-kutoka_uwanja_wa_ndege_jina': 46,\n",
              " 'I-ndege_mod': 47,\n",
              " 'I-kuondoka_muda.kipindi': 48,\n",
              " 'B-acha_mji_jina': 49,\n",
              " 'B-ndege_days': 50,\n",
              " 'I-ndege_days': 51,\n",
              " 'B-uchumi': 52,\n",
              " 'B-kuondoka_terehe.tarehe_jamaa': 53,\n",
              " 'B-uwanjya_wa_ndege_kanuni': 54,\n",
              " 'B-kufika_tarehe.siku_jina': 55,\n",
              " 'B-ndege_number': 56,\n",
              " 'I-mlo_maelezo': 57,\n",
              " 'B-kuondoka_tarehe.tarehe_jamaa': 58,\n",
              " 'B-kufika_muda.kipindi_cha_siku': 59,\n",
              " 'B-kufika_muda.kuanza_muda': 60,\n",
              " 'B-kufika_muda.mwisho_muda': 61,\n",
              " 'I-kufika_muda.mwisho_muda': 62,\n",
              " 'B-bila_kurudi': 63,\n",
              " 'I-bila_kurudi': 64,\n",
              " 'B-depart_time.period_mod': 65,\n",
              " 'I-safari_kurudi': 66,\n",
              " 'I-chakula_nambari_description': 67,\n",
              " 'I-safiri_bila_kurudi': 68,\n",
              " 'B-kuunganisha': 69,\n",
              " 'B-kutoka_uwanja_wa_ndege_kanuni': 70,\n",
              " 'I-acha_mji_jina': 71,\n",
              " 'I-kutoka_uwanja_wa_ndege_jina': 72,\n",
              " 'B-kuondoka_terehe.leo_jamaa': 73,\n",
              " 'B-hadi.jina_la_jimbo': 74,\n",
              " 'B-usafiri_aina': 75,\n",
              " 'I-uwanjya_wa_ndege_jina': 76,\n",
              " 'B-hadi_uwanja_wa_ndege_kanuni': 77,\n",
              " 'B-mlo_maelezo': 78,\n",
              " 'B-chakula_nambari_description': 79,\n",
              " 'B-kizuizi_kanuni': 80,\n",
              " 'B-hadi_uwanja_wa_ndege_jina': 81,\n",
              " 'B-kuondoka_terehe.mwaka': 82,\n",
              " 'B-safari_kurudi': 83,\n",
              " 'B-safiri_bila_kurudi': 84,\n",
              " 'B-kufika_tarehe.siku_nambari': 85,\n",
              " 'I-kizuizi_kanuni': 86,\n",
              " 'B-kipicha_cha_siku': 87,\n",
              " 'B-ndege_hali': 88,\n",
              " 'B-acha.mji_jina': 89,\n",
              " 'B-nauli_kiasi': 90,\n",
              " 'I-nauli_kiasi': 91,\n",
              " 'B-kurudi_tarehe.siku_jamaa': 92,\n",
              " 'I-kufika_muda.muda_jamaa': 93,\n",
              " 'B-kuondoka_tarehe.leo_jamaa': 94,\n",
              " 'B-kuondoka_muda.kuanza_muda': 95,\n",
              " 'B-kuondoka_muda.mwisho_muda': 96,\n",
              " 'B-siku_kanuni': 97,\n",
              " 'B-kupitia.mji_jina': 98,\n",
              " 'B-kutoka.jina_la_jimbo': 99,\n",
              " 'I-kuunganisha': 100,\n",
              " 'B-kuondoka.jina_la_jimbo': 101,\n",
              " 'I-usafiri_aina': 102,\n",
              " 'I-kipicha_cha_siku': 103,\n",
              " 'B-kuondoka.wakati_jamaa': 104,\n",
              " 'B-kurudi_tarehe.siku_jina': 105,\n",
              " 'I-ndege_hali': 106,\n",
              " 'I-hadi_uwanja_wa_ndege_jina': 107,\n",
              " 'B-kufika_terehe.mwezi_jina': 108,\n",
              " 'I-darasa_aina': 109,\n",
              " 'B-kuondoka_saa.wakati_jamaa': 110,\n",
              " 'B-kuondoka_wakati.wakati': 111,\n",
              " 'I-kuondoka_wakati.wakati': 112,\n",
              " 'B-au': 113,\n",
              " 'B-ndege_nambari': 114,\n",
              " 'I-kufika_muda.kuanza_muda': 115,\n",
              " 'I-acha.mji_jina': 116,\n",
              " 'B-uwanja_wa_ndege_jina': 117,\n",
              " 'I-kurudi_tarehe.siku_jamaa': 118,\n",
              " 'I-kuondoka_muda.kipindi_cha_siku': 119,\n",
              " 'B-hadi.jimbo_jina': 120,\n",
              " 'B-kufika_tarehe.mwezi_jina': 121,\n",
              " 'B-kuondoka.mji_jina': 122,\n",
              " 'I-kuondoka.mji_jina': 123,\n",
              " 'B-kutoka_muda.kipindi_cha_siku': 124,\n",
              " 'I-kuondoka_muda.mwisho_muda': 125,\n",
              " 'B-bila_kukoma': 126,\n",
              " 'I-bila_kukoma': 127,\n",
              " 'B-kufika_muda.mwisho_muda.kipindi_cha_siku': 128,\n",
              " 'B-kuweka_nafasi_aina': 129,\n",
              " 'B-kuondoka_terehe.kesho': 130,\n",
              " 'B-kurudi_tarehe.tarehe_jamaa': 131,\n",
              " 'I-kurudi_tarehe.tarehe_jamaa': 132,\n",
              " 'I-kupitia.mji_jina': 133,\n",
              " 'B-darasa_aina': 134,\n",
              " 'B-mapumziko': 135,\n",
              " 'B-kuodoka_tarehe.leo_jamaa': 136,\n",
              " 'B-kufika_tarehe.tarehe_jamaa': 137,\n",
              " 'B-kutoka_mji_kanuni': 138,\n",
              " 'B-siku_jina': 139,\n",
              " 'B-acha_uwanja_wa_ndege_kanuni': 140,\n",
              " 'B-bila_kikomo': 141,\n",
              " 'I-bila_kikomo': 142,\n",
              " 'I-B-kuondoka_tarehe.siku_jina': 143}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8CX6LxYmhRh"
      },
      "source": [
        "The following function generates token-aligned integer labels from the BIO word-level annotations. In particular, if a specific word is too long to be represented as a single token, we expand its label for all the tokens of that word while taking care of using \"B-\" labels only for the first token and then use \"I-\" for the matching slot type for subsequent tokens of the same word:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LLkBWFJM6tr"
      },
      "source": [
        "def encode_token_labels(text_sequences, slot_names, tokenizer, slot_map,max_length):\n",
        "  \n",
        "    encoded = np.zeros(shape=(len(text_sequences), max_length), dtype=np.int32)\n",
        "    for i, (text_sequence, word_labels) in enumerate(\n",
        "            zip(text_sequences, slot_names)):\n",
        "        encoded_labels = []\n",
        "        for word, word_label in zip(text_sequence.split(), word_labels.split()):\n",
        "            tokens = tokenizer.tokenize(word)\n",
        "            encoded_labels.append(slot_map[word_label])\n",
        "            expand_label = word_label.replace(\"B-\", \"I-\")\n",
        "            if not expand_label in slot_map:\n",
        "                expand_label = word_label\n",
        "            encoded_labels.extend([slot_map[expand_label]] * (len(tokens) - 1))\n",
        "        encoded[i, 1:len(encoded_labels) + 1] = encoded_labels\n",
        "    return encoded\n",
        "\n",
        "slot_train = encode_token_labels(\n",
        "    df_train[\"words\"], df_train[\"word_labels\"], tokenizer, slot_map, 60)\n",
        "slot_valid = encode_token_labels(\n",
        "    df_valid[\"words\"], df_valid[\"word_labels\"], tokenizer, slot_map, 60)\n",
        "# slot_test = encode_token_labels(\n",
        "#     df_test[\"words\"], df_test[\"word_labels\"], tokenizer, slot_map, 90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "######### Debbuging proccess\n",
        "\n",
        "slot_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1agpFmmA4fJ",
        "outputId": "3477be8f-774d-4a4c-b679-e4ff4482dd30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  3,  6,  1,  2,  4,  5,  5,  5, 10, 48, 48,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slot_valid[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqjvB3jXCnfP",
        "outputId": "cf5f8033-0de6-440b-9baf-72046a446e57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 6,\n",
              "       6, 1, 2, 4, 1, 1, 3, 6, 1, 2, 4, 4, 1, 1, 1, 3, 6, 6, 1, 2, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slot_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYfBulefDZqu",
        "outputId": "b242cdaf-0d6d-4183-c1f5-1675519e890b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'[PAD]': 0,\n",
              " 'O': 1,\n",
              " 'B-hadi.mji_jina': 2,\n",
              " 'B-kutoka_mji_jina': 3,\n",
              " 'I-hadi.mji_jina': 4,\n",
              " 'B-kuondoka_terehe.siku_jina': 5,\n",
              " 'I-kutoka_mji_jina': 6,\n",
              " 'B-ndege_jina': 7,\n",
              " 'cha': 8,\n",
              " 'siku': 9,\n",
              " 'B-kuondoka_muda.kipindi': 10,\n",
              " 'I-safari_ya_kurudi': 11,\n",
              " 'B-kutoka.mji_jina': 12,\n",
              " 'B-hadi_mji_jina': 13,\n",
              " 'I-kufika_muda.muda': 14,\n",
              " 'B-ndege_kanuni': 15,\n",
              " 'I-kuondoka_muda.muda': 16,\n",
              " 'I-ndege_jina': 17,\n",
              " 'B-safari_ya_kurudi': 18,\n",
              " 'B-mji_jina': 19,\n",
              " 'B-kuondoka_muda.muda_jamaa': 20,\n",
              " 'B-kuondoka_muda.muda': 21,\n",
              " 'B-kuondoka_tarehe.siku_jina': 22,\n",
              " 'B-kufika_muda.muda': 23,\n",
              " 'I-ndege_acha': 24,\n",
              " 'I-hadi_mji_jina': 25,\n",
              " 'B-gharama_jamaa': 26,\n",
              " 'I-kategoria_aina': 27,\n",
              " 'B-kuondoka_muda.kipindi_cha_siku': 28,\n",
              " 'I-kuondoka_terehe.siku_nambari': 29,\n",
              " 'I-gharama_jamaa': 30,\n",
              " 'I-kutoka.mji_jina': 31,\n",
              " 'B-chakula_nambari': 32,\n",
              " 'B-ndege_mod': 33,\n",
              " 'B-ndege_acha': 34,\n",
              " 'I-mji_jina': 35,\n",
              " 'B-kufika_muda.muda_jamaa': 36,\n",
              " 'B-kategoria_aina': 37,\n",
              " 'I-uchumi': 38,\n",
              " 'B-kuondoka_terehe.mwezi_jina': 39,\n",
              " 'B-kuondoka_terehe.siku_nambari': 40,\n",
              " 'I-kuondoka_tarehe.siku_nambari': 41,\n",
              " 'B-kuondoka_tarehe.siku_nambari': 42,\n",
              " 'B-msimbo_msingi_wa_nauli': 43,\n",
              " 'B-kuondoka_tarehe.mwezi_jina': 44,\n",
              " 'B-uwanjya_wa_ndege_jina': 45,\n",
              " 'B-kutoka_uwanja_wa_ndege_jina': 46,\n",
              " 'I-ndege_mod': 47,\n",
              " 'I-kuondoka_muda.kipindi': 48,\n",
              " 'B-acha_mji_jina': 49,\n",
              " 'B-ndege_days': 50,\n",
              " 'I-ndege_days': 51,\n",
              " 'B-uchumi': 52,\n",
              " 'B-kuondoka_terehe.tarehe_jamaa': 53,\n",
              " 'B-uwanjya_wa_ndege_kanuni': 54,\n",
              " 'B-kufika_tarehe.siku_jina': 55,\n",
              " 'B-ndege_number': 56,\n",
              " 'I-mlo_maelezo': 57,\n",
              " 'B-kuondoka_tarehe.tarehe_jamaa': 58,\n",
              " 'B-kufika_muda.kipindi_cha_siku': 59,\n",
              " 'B-kufika_muda.kuanza_muda': 60,\n",
              " 'B-kufika_muda.mwisho_muda': 61,\n",
              " 'I-kufika_muda.mwisho_muda': 62,\n",
              " 'B-bila_kurudi': 63,\n",
              " 'I-bila_kurudi': 64,\n",
              " 'B-depart_time.period_mod': 65,\n",
              " 'I-safari_kurudi': 66,\n",
              " 'I-chakula_nambari_description': 67,\n",
              " 'I-safiri_bila_kurudi': 68,\n",
              " 'B-kuunganisha': 69,\n",
              " 'B-kutoka_uwanja_wa_ndege_kanuni': 70,\n",
              " 'I-acha_mji_jina': 71,\n",
              " 'I-kutoka_uwanja_wa_ndege_jina': 72,\n",
              " 'B-kuondoka_terehe.leo_jamaa': 73,\n",
              " 'B-hadi.jina_la_jimbo': 74,\n",
              " 'B-usafiri_aina': 75,\n",
              " 'I-uwanjya_wa_ndege_jina': 76,\n",
              " 'B-hadi_uwanja_wa_ndege_kanuni': 77,\n",
              " 'B-mlo_maelezo': 78,\n",
              " 'B-chakula_nambari_description': 79,\n",
              " 'B-kizuizi_kanuni': 80,\n",
              " 'B-hadi_uwanja_wa_ndege_jina': 81,\n",
              " 'B-kuondoka_terehe.mwaka': 82,\n",
              " 'B-safari_kurudi': 83,\n",
              " 'B-safiri_bila_kurudi': 84,\n",
              " 'B-kufika_tarehe.siku_nambari': 85,\n",
              " 'I-kizuizi_kanuni': 86,\n",
              " 'B-kipicha_cha_siku': 87,\n",
              " 'B-ndege_hali': 88,\n",
              " 'B-acha.mji_jina': 89,\n",
              " 'B-nauli_kiasi': 90,\n",
              " 'I-nauli_kiasi': 91,\n",
              " 'B-kurudi_tarehe.siku_jamaa': 92,\n",
              " 'I-kufika_muda.muda_jamaa': 93,\n",
              " 'B-kuondoka_tarehe.leo_jamaa': 94,\n",
              " 'B-kuondoka_muda.kuanza_muda': 95,\n",
              " 'B-kuondoka_muda.mwisho_muda': 96,\n",
              " 'B-siku_kanuni': 97,\n",
              " 'B-kupitia.mji_jina': 98,\n",
              " 'B-kutoka.jina_la_jimbo': 99,\n",
              " 'I-kuunganisha': 100,\n",
              " 'B-kuondoka.jina_la_jimbo': 101,\n",
              " 'I-usafiri_aina': 102,\n",
              " 'I-kipicha_cha_siku': 103,\n",
              " 'B-kuondoka.wakati_jamaa': 104,\n",
              " 'B-kurudi_tarehe.siku_jina': 105,\n",
              " 'I-ndege_hali': 106,\n",
              " 'I-hadi_uwanja_wa_ndege_jina': 107,\n",
              " 'B-kufika_terehe.mwezi_jina': 108,\n",
              " 'I-darasa_aina': 109,\n",
              " 'B-kuondoka_saa.wakati_jamaa': 110,\n",
              " 'B-kuondoka_wakati.wakati': 111,\n",
              " 'I-kuondoka_wakati.wakati': 112,\n",
              " 'B-au': 113,\n",
              " 'B-ndege_nambari': 114,\n",
              " 'I-kufika_muda.kuanza_muda': 115,\n",
              " 'I-acha.mji_jina': 116,\n",
              " 'B-uwanja_wa_ndege_jina': 117,\n",
              " 'I-kurudi_tarehe.siku_jamaa': 118,\n",
              " 'I-kuondoka_muda.kipindi_cha_siku': 119,\n",
              " 'B-hadi.jimbo_jina': 120,\n",
              " 'B-kufika_tarehe.mwezi_jina': 121,\n",
              " 'B-kuondoka.mji_jina': 122,\n",
              " 'I-kuondoka.mji_jina': 123,\n",
              " 'B-kutoka_muda.kipindi_cha_siku': 124,\n",
              " 'I-kuondoka_muda.mwisho_muda': 125,\n",
              " 'B-bila_kukoma': 126,\n",
              " 'I-bila_kukoma': 127,\n",
              " 'B-kufika_muda.mwisho_muda.kipindi_cha_siku': 128,\n",
              " 'B-kuweka_nafasi_aina': 129,\n",
              " 'B-kuondoka_terehe.kesho': 130,\n",
              " 'B-kurudi_tarehe.tarehe_jamaa': 131,\n",
              " 'I-kurudi_tarehe.tarehe_jamaa': 132,\n",
              " 'I-kupitia.mji_jina': 133,\n",
              " 'B-darasa_aina': 134,\n",
              " 'B-mapumziko': 135,\n",
              " 'B-kuodoka_tarehe.leo_jamaa': 136,\n",
              " 'B-kufika_tarehe.tarehe_jamaa': 137,\n",
              " 'B-kutoka_mji_kanuni': 138,\n",
              " 'B-siku_jina': 139,\n",
              " 'B-acha_uwanja_wa_ndege_kanuni': 140,\n",
              " 'B-bila_kikomo': 141,\n",
              " 'I-bila_kikomo': 142,\n",
              " 'I-B-kuondoka_tarehe.siku_jina': 143}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # def encode_token_labels(text_sequences, slot_names, tokenizer, slot_map,max_length):\n",
        "\n",
        "# text_sequences = df_train[\"words\"]\n",
        "# slot_names = df_train[\"word_labels\"]\n",
        "# slot_map = slot_map\n",
        "# max_length  = 63\n",
        "\n",
        "# encoded = np.zeros(shape=(len(text_sequences), max_length), dtype=np.int32)\n",
        "# for i, (text_sequence, word_labels) in enumerate(\n",
        "#         zip(text_sequences, slot_names)):\n",
        "#     encoded_labels = []\n",
        "\n",
        "#     for word, word_label in zip(text_sequence.split(), word_labels.split()):\n",
        "\n",
        "#         tokens = tokenizer.tokenize(word)\n",
        "#         # print(word_label)\n",
        "\n",
        "#         encoded_labels.append(slot_map[word_label])\n",
        "\n",
        "#         expand_label = word_label.replace(\"B-\", \"I-\")\n",
        "\n",
        "#         if not expand_label in slot_map:\n",
        "\n",
        "#             expand_label = word_label\n",
        "#         encoded_labels.extend([slot_map[expand_label]] * (len(tokens) - 1))\n",
        "#     encoded[i, 1:len(encoded_labels) + 1] = encoded_labels\n",
        "\n",
        "# # print(encoded)\n",
        "\n",
        "# slot_train = encode_token_labels(\n",
        "#     df_train[\"words\"], df_train[\"word_labels\"], tokenizer, slot_map, 63)\n",
        "# slot_valid = encode_token_labels(\n",
        "#     df_valid[\"words\"], df_valid[\"word_labels\"], tokenizer, slot_map, 63)\n",
        "# slot_test = encode_token_labels(\n",
        "#     df_test[\"words\"], df_test[\"word_labels\"], tokenizer, slot_map, 63)"
      ],
      "metadata": {
        "id": "BOLFQGIgEmY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train[\"words\"][0]"
      ],
      "metadata": {
        "id": "aIs1xOdkHU7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train[\"word_labels\"][0]"
      ],
      "metadata": {
        "id": "L7WAu26sG75s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "slot_map['O']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDgOINVrF8Un",
        "outputId": "5f79f8c2-f8ed-4e6d-a59b-2d221731b2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n33S5n-TnVjd"
      },
      "source": [
        "Note that the special tokens such as \"[PAD]\" and \"[SEP]\" and all padded positions recieve a 0 label."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Joint Intent And Slot Filling Model"
      ],
      "metadata": {
        "id": "LATnIrGKiMzO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwkvLq3KzU4G"
      },
      "source": [
        "class JointIntentAndSlotFillingModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, intent_num_labels=None, slot_num_labels=None,\n",
        "                 model_name=\"bert-base-multilingual-cased\", dropout_prob=0.1):\n",
        "        super().__init__(name=\"joint_intent_slot\")\n",
        "        self.bert = TFAutoModel.from_pretrained(model_name)\n",
        "        self.dropout = Dropout(dropout_prob)\n",
        "        self.intent_classifier = Dense(intent_num_labels,\n",
        "                                       name=\"intent_classifier\")\n",
        "        self.slot_classifier = Dense(slot_num_labels,\n",
        "                                     name=\"slot_classifier\")\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        sequence_output, pooled_output = self.bert(inputs, training=training)\n",
        "\n",
        "        # The first output of the main BERT layer has shape:\n",
        "        # (batch_size, max_length, output_dim)\n",
        "        sequence_output = self.dropout(sequence_output, training=training)\n",
        "        slot_logits = self.slot_classifier(sequence_output)\n",
        "\n",
        "        # The second output of the main BERT layer has shape:\n",
        "        # (batch_size, output_dim)\n",
        "        # and gives a \"pooled\" representation for the full sequence from the\n",
        "        # hidden state that corresponds to the \"[CLS]\" token.\n",
        "        pooled_output = self.dropout(pooled_output, training=training)\n",
        "        intent_logits = self.intent_classifier(pooled_output)\n",
        "\n",
        "        return slot_logits, intent_logits\n",
        "\n",
        "joint_model = JointIntentAndSlotFillingModel(intent_num_labels=len(intent_map), slot_num_labels=len(slot_map))\n",
        "        \n",
        "# joint_model.compile(optimizer=Adam(learning_rate=3e-5, epsilon=1e-08),loss=losses)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCPRwf2Czf_d"
      },
      "source": [
        "opt = Adam(learning_rate=3e-5, epsilon=1e-08)\n",
        "losses = [SparseCategoricalCrossentropy(from_logits=True),\n",
        "          SparseCategoricalCrossentropy(from_logits=True)]\n",
        "metrics = [SparseCategoricalAccuracy('accuracy')]\n",
        "joint_model.compile(optimizer=opt, loss=losses, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8A0qr1K2Q-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16482dcf-bf6d-4640-e409-740663ac8b48"
      },
      "source": [
        "history = joint_model.fit(encoded_train, (slot_train, intent_train),validation_data=(encoded_valid, (slot_valid, intent_valid)), epochs=15, batch_size=8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "90/90 [==============================] - 535s 6s/step - loss: 2.0491 - output_1_loss: 0.6802 - output_2_loss: 1.3689 - output_1_accuracy: 0.8692 - output_2_accuracy: 0.7031 - val_loss: 1.5885 - val_output_1_loss: 0.4957 - val_output_2_loss: 1.0928 - val_output_1_accuracy: 0.8986 - val_output_2_accuracy: 0.7374\n",
            "Epoch 2/15\n",
            "90/90 [==============================] - 529s 6s/step - loss: 1.4621 - output_1_loss: 0.4856 - output_2_loss: 0.9766 - output_1_accuracy: 0.9037 - output_2_accuracy: 0.7297 - val_loss: 1.0786 - val_output_1_loss: 0.4110 - val_output_2_loss: 0.6676 - val_output_1_accuracy: 0.9166 - val_output_2_accuracy: 0.8492\n",
            "Epoch 3/15\n",
            "90/90 [==============================] - 530s 6s/step - loss: 1.0712 - output_1_loss: 0.4064 - output_2_loss: 0.6648 - output_1_accuracy: 0.9215 - output_2_accuracy: 0.8445 - val_loss: 0.9250 - val_output_1_loss: 0.3831 - val_output_2_loss: 0.5419 - val_output_1_accuracy: 0.9244 - val_output_2_accuracy: 0.8603\n",
            "Epoch 4/15\n",
            "90/90 [==============================] - 529s 6s/step - loss: 0.7906 - output_1_loss: 0.3586 - output_2_loss: 0.4320 - output_1_accuracy: 0.9290 - output_2_accuracy: 0.8894 - val_loss: 0.6971 - val_output_1_loss: 0.3525 - val_output_2_loss: 0.3446 - val_output_1_accuracy: 0.9289 - val_output_2_accuracy: 0.8939\n",
            "Epoch 5/15\n",
            "90/90 [==============================] - 532s 6s/step - loss: 0.6181 - output_1_loss: 0.3161 - output_2_loss: 0.3020 - output_1_accuracy: 0.9363 - output_2_accuracy: 0.9230 - val_loss: 0.4846 - val_output_1_loss: 0.3266 - val_output_2_loss: 0.1580 - val_output_1_accuracy: 0.9338 - val_output_2_accuracy: 0.9385\n",
            "Epoch 6/15\n",
            "90/90 [==============================] - 534s 6s/step - loss: 0.4438 - output_1_loss: 0.2813 - output_2_loss: 0.1624 - output_1_accuracy: 0.9405 - output_2_accuracy: 0.9566 - val_loss: 0.4475 - val_output_1_loss: 0.3311 - val_output_2_loss: 0.1163 - val_output_1_accuracy: 0.9342 - val_output_2_accuracy: 0.9777\n",
            "Epoch 7/15\n",
            "90/90 [==============================] - 530s 6s/step - loss: 0.3633 - output_1_loss: 0.2535 - output_2_loss: 0.1098 - output_1_accuracy: 0.9447 - output_2_accuracy: 0.9720 - val_loss: 0.4096 - val_output_1_loss: 0.3099 - val_output_2_loss: 0.0997 - val_output_1_accuracy: 0.9355 - val_output_2_accuracy: 0.9609\n",
            "Epoch 8/15\n",
            "88/90 [============================>.] - ETA: 11s - loss: 0.2786 - output_1_loss: 0.2178 - output_2_loss: 0.0608 - output_1_accuracy: 0.9511 - output_2_accuracy: 0.9886"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KISsxUXO6aA1"
      },
      "source": [
        "#Making prediction on a single text sequence and displaying both the sequence-wise and the token-wise class labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0hZKphof3Im"
      },
      "source": [
        "# def show_predictions(text, tokenizer, model, intent_names, slot_names):\n",
        "  \n",
        "#     inputs = tf.constant(tokenizer.encode(text))[None, :]  # batch_size = 1\n",
        "#     outputs = model(inputs)\n",
        "#     slot_logits, intent_logits = outputs\n",
        "#     slot_ids = slot_logits.numpy().argmax(axis=-1)[0, 1:-1]\n",
        "#     intent_id = intent_logits.numpy().argmax(axis=-1)[0]\n",
        "#     intent = [k for k, v in intent_names.items() if v == intent_id]\n",
        "\n",
        "#     print(\"## Intent:\", intent)\n",
        "#     print(\"## Slots:\")\n",
        "#     for token, slot_id in zip(tokenizer.tokenize(text), slot_ids):\n",
        "#       # slot = [k for k, v in slot_names.items() if v == slot_ids]\n",
        "#       # print(token, slot_id)\n",
        "#       # print(slot_names[slot_id])\n",
        "#       print(f\"{token} : {slot_names[slot_id]}\")\n",
        "\n",
        "#       # break\n",
        "    \n",
        "#       # print(f\"{token:>10} : {slot_names[slot_id]}\")\n",
        "\n",
        "def show_predictions(text, tokenizer, model, intent_names, slot_names):\n",
        "\n",
        "    inputs = tf.constant(tokenizer.encode(text))[None, :]  # batch_size = 1\n",
        "    # print(inputs)\n",
        "    outputs = model(inputs)\n",
        "    slot_logits, intent_logits = outputs\n",
        "    # print(outputs)\n",
        "    slot_ids = slot_logits.numpy().argmax(axis=-1)[0, 1:-1]\n",
        "    # print(slot_ids)\n",
        "    intent_id = intent_logits.numpy().argmax(axis=-1)[0]\n",
        "    intent = [k for k, v in intent_names.items() if v == intent_id]\n",
        "\n",
        "    # print(slot_ids)\n",
        "\n",
        "    print(\"## Intent:\", intent)\n",
        "    print(\"## Slots:\")\n",
        "    slot_pred = []\n",
        "    \n",
        "    ####\n",
        "    text_split = text.split(' ')\n",
        "    tokens_ids = [(i,j) for i,j in zip(tokenizer.tokenize(text),slot_ids)]\n",
        "    #### Removing ## Tokens\n",
        "    tokens_ids_ = [x for x in tokens_ids if not '##' in x[0]]\n",
        "\n",
        "\n",
        "    for token, slot_id in zip(text_split, tokens_ids_):\n",
        "      # slot = [k for k, v in slot_names.items() if v == slot_ids]\n",
        "      # print(token, slot_id)\n",
        "      # print()\n",
        "      # print(token)\n",
        "\n",
        "      # print(token)\n",
        "      print(f\"{token} : {slot_names[slot_id[1]]}\")\n",
        "      slot_pred.append(slot_names[slot_id[1]])\n",
        "\n",
        "    return intent, slot_pred\n",
        "\n",
        "      # break\n",
        "        \n",
        "      # print(f\"{token:>10} : {slot_names[slot_id]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# slot_names"
      ],
      "metadata": {
        "id": "lDm5q6qYcRGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_valid.iloc[0][\"words\"]\n",
        "df_valid.iloc[0][\"word_labels\"]"
      ],
      "metadata": {
        "id": "gBfbYCPZ1jZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzzVtd7ag7Hi"
      },
      "source": [
        "pred_intent, pred_slot = show_predictions(df_valid.iloc[0][\"words\"], tokenizer, joint_model, intent_map, slot_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_slot\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "avg_f1_score = []\n",
        "\n",
        "for idx in range(len(df_valid)):\n",
        "  f1 = f1_score(df_valid.iloc[idx][\"word_labels\"].split(\" \"), pred_slot, average=\"micro\")\n",
        "  avg_f1_score.append(f1)\n",
        "# df_valid.iloc[0][\"word_labels\"].split(\" \"), pred_slot\n",
        "\n",
        "\n",
        "np.mean(avg_f1_score)"
      ],
      "metadata": {
        "id": "sWuVXQWE0iTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRIIpxojhMBK"
      },
      "source": [
        "show_predictions(\"niyihe funguro zitangwa murugendo rwabanyamerika 811 kuva tampa kugera milwaukee\",\n",
        "                 tokenizer, joint_model, intent_map, slot_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# O O O O B-kuva.umujyi_izina B-igihe_umunsi I-igihe_umunsi O B-kugera.umujyi_izina O   B-igihe_umunsi"
      ],
      "metadata": {
        "id": "OCpydUWx3Ahm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3UCKzNchAtF"
      },
      "source": [
        "show_predictions(\"izo ndege zirahaguruka kuwa kabiri kuva montreal zikagera muri chicago mugitondo\",\n",
        "                 tokenizer, joint_model, intent_map, slot_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_predictions(\"kwerekana indege kuva burbank kuri st. louis on monday\",\n",
        "                 tokenizer, joint_model, intent_map, slot_names)"
      ],
      "metadata": {
        "id": "B2-HW5Ay31yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "# from transformers import pipeline\n",
        "# model_name = 'mbeukman/xlm-roberta-base-finetuned-ner-kinyarwanda'\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "\n",
        "# nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "# example = \"Ambasaderi wa EU mu Rwanda , Nicola Bellomo yagize ati  Inkunga yacu ni imwe mu nkunga yagutse yiswe # TeamEurope .\"\n",
        "\n",
        "# ner_results = nlp(example)\n",
        "# print(ner_results)"
      ],
      "metadata": {
        "id": "p3N-_igFe_lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "# from transformers import pipeline\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "# model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "\n",
        "# nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "# example = \"My name is Wolfgang and I live in Berlin\"\n",
        "\n",
        "# ner_results = nlp(example)\n",
        "# print(ner_results)"
      ],
      "metadata": {
        "id": "ZxkO6_0uq6xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "# from transformers import pipeline\n",
        "# model_name = 'mbeukman/xlm-roberta-base-finetuned-kinyarwanda-finetuned-ner-kinyarwanda'\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "\n",
        "# nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "# example = \"Ambasaderi wa EU mu Rwanda , Nicola Bellomo yagize ati  Inkunga yacu ni imwe mu nkunga yagutse yiswe # TeamEurope .\"\n",
        "\n",
        "# ner_results = nlp(example)\n",
        "# print(ner_results)\n"
      ],
      "metadata": {
        "id": "7mcSS6BfrFxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XLM and roberta"
      ],
      "metadata": {
        "id": "UNWbz9ysrlhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vNpLVuMsru04"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}